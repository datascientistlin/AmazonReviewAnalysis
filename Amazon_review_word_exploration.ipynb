{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't put any google trends data here since we are only exploring amazon reviews in this notebook.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def GetMergedAmazonDataFrames():\n",
    "#     files_to_use = [r'data\\AirPods Pro.csv', r'data\\Elite 75t.csv',r'data\\Free.csv',\n",
    "#                    r'data\\Galaxy Buds Plus.csv',r'data\\M-200.csv',r'data\\NC700.csv',\n",
    "#                    r'data\\Soundcore Liberty 2 Pro.csv',r'data\\Soundcore Liberty Air 2.csv',r'data\\Soundcore Life Q20.csv',\n",
    "#                    r'data\\WF-1000XM3.csv']\n",
    "    files_to_use = [r'data\\AirPods Pro.csv', r'data\\Elite 75t.csv',r'data\\Free.csv',\n",
    "                   r'data\\Galaxy Buds Plus.csv',r'data\\NC700.csv',\n",
    "                   r'data\\Soundcore Liberty 2 Pro.csv',r'data\\Soundcore Liberty Air 2.csv',r'data\\Soundcore Life Q20.csv',\n",
    "                   r'data\\WF-1000XM3.csv']\n",
    "    \n",
    "    amzn_df = pd.read_csv(files_to_use[0],  parse_dates=False)\n",
    "    for file in files_to_use[1:]:\n",
    "        df = pd.read_csv(file,  parse_dates=False)\n",
    "#         amzn_df = pd.merge(amzn_df, df, how='outer',on='review_date')\n",
    "        amzn_df = pd.concat([amzn_df,df],sort=False)\n",
    "        \n",
    "    amzn_df['review_date'] = pd.to_datetime(amzn_df['review_date'], format='%Y-%m-%d')\n",
    "    amzn_df = amzn_df[['Manufacturer', 'ProductName', 'review_rating', 'verified_purchase',\n",
    "       'review_date', 'review_title', 'review_text']]\n",
    "    return amzn_df\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def GetAmazonTextReviewsDf():\n",
    "    ### This function is used to prepare \n",
    "    #   the data frame to word and text analysis.. ####\n",
    "    amzn_df = GetMergedAmazonDataFrames()\n",
    "    columns = ['Manufacturer', 'ProductName', 'review_rating', 'verified_purchase',\n",
    "       'review_date', 'review_title', 'review_text']\n",
    "    \n",
    "    amzn_df=amzn_df[columns]\n",
    "    return amzn_df\n",
    "#     amzn_df['totalReviews'] =\n",
    "    \n",
    "def GetAmazonNumericalReviewsDf():\n",
    "    amzn_df = GetMergedAmazonDataFrames()\n",
    "    columns = ['Manufacturer', 'ProductName', 'review_rating', 'verified_purchase',\n",
    "       'review_date']\n",
    "    \n",
    "    amzn_df=amzn_df[columns]\n",
    "    # split into two data sets for purchased and not purchased.\n",
    "    amzn_purchased = amzn_df.where(amzn_df['verified_purchase']== 1).dropna()\n",
    "    amzn_notPurchased = amzn_df.where(amzn_df['verified_purchase']== 0).dropna()\n",
    "    \n",
    "    tempdf = None\n",
    "    for product in amzn_purchased['ProductName'].unique():\n",
    "        df = amzn_purchased.where(amzn_purchased['ProductName'] == product).dropna()\n",
    "        \n",
    "        manufacturer = df['Manufacturer'].unique()[0]\n",
    "        df= df[['review_rating','review_date']]\n",
    "        \n",
    "        dfCount = df\n",
    "        df = df.set_index('review_date').resample('W-SAT').mean().reset_index()#.agg(['mean','count']).reset_index()\n",
    "#         df['review_rating'] = df['review_rating'].fillna(0)\n",
    "        df['review_rating_norm'] = Normalize(df['review_rating'].fillna(df['review_rating'].mean()))\n",
    "        df['ProductName'] = df['review_rating'].apply(lambda x: product)\n",
    "        df['Manufacturer'] = df['review_rating'].apply(lambda x: manufacturer)\n",
    "        df['verified_purchase'] = df['review_rating'].apply(lambda x: '1')\n",
    "        df['count'] = dfCount[['review_rating','review_date']].set_index('review_date').resample('W-SAT').count().reset_index()['review_rating']\n",
    "#         print(df.head())\n",
    "        if tempdf is None:\n",
    "            tempdf = df\n",
    "        else:\n",
    "            tempdf = pd.concat([tempdf, df])\n",
    "            \n",
    "    \n",
    "    for product in amzn_notPurchased['ProductName'].unique():\n",
    "        df = amzn_notPurchased.where(amzn_notPurchased['ProductName'] == product).dropna()\n",
    "        \n",
    "        manufacturer = df['Manufacturer'].unique()[0]\n",
    "        df= df[['review_rating','review_date']]\n",
    "        \n",
    "        dfCount = df\n",
    "        \n",
    "        \n",
    "        df = df.set_index('review_date').resample('W-SAT').mean().reset_index()#.agg(['mean','count']).reset_index()\n",
    "#         df['review_rating'] = df['review_rating'].fillna(0)\n",
    "        df['review_rating_norm'] = Normalize(df['review_rating'].fillna(df['review_rating'].mean()))\n",
    "        df['ProductName'] = df['review_rating'].apply(lambda x: product)\n",
    "        df['Manufacturer'] = df['review_rating'].apply(lambda x: manufacturer)\n",
    "        df['verified_purchase'] = df['review_rating'].apply(lambda x: '0')\n",
    "        df['count'] = dfCount[['review_rating','review_date']].set_index('review_date').resample('W-SAT').count().reset_index()['review_rating']\n",
    "        \n",
    "#         print(df.head())\n",
    "        if tempdf is None:\n",
    "            tempdf = df\n",
    "        else:\n",
    "            tempdf = pd.concat([tempdf, df])\n",
    "            \n",
    "    return tempdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(array):\n",
    "    return array / np.linalg.norm(array, ord=1)\n",
    "    \n",
    "# Sav-golay filter for averaging.\n",
    "def savGolay(array, window = 9, order =7):\n",
    "    from scipy.ndimage import convolve1d\n",
    "    from scipy.signal import savgol_coeffs, savgol_filter\n",
    "    from scipy.signal._savitzky_golay import _polyder\n",
    "    return savgol_filter(array, window, order)\n",
    "   \n",
    "# Simple Moving Average used in financial data.\n",
    "def SMA(pandas_df_daily,columnName, dayWindowSize=20):\n",
    "    daily_close_df = pandas_df_daily[columnName].copy()\n",
    "    return daily_close_df.rolling(dayWindowSize).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for working with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AngryGamers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\AngryGamers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "\n",
    "def TokenizeText(text):\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#     text = \"This is my text. It includes commas, question marks? and other stuff. Also U.S..\".lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def GetWordsAndTheirTags(text):\n",
    "    text = CleanText(text)\n",
    "    tokens = TokenizeText(text)\n",
    "    return nltk.pos_tag(tokens)\n",
    "\n",
    "def CleanText(text):\n",
    "    text=str(text)\n",
    "    text= text.lower().replace(\"wouldn\\'t\",\"would not\")\n",
    "    return text\n",
    "def helperGetWordsWithTokenType(text, t):   \n",
    "# #     print(nltk.help.upenn_tagset('PRP$'))\n",
    "# #     print(text)\n",
    "#     text = CleanText(text)\n",
    "#     tokens = TokenizeText(text)\n",
    "# #     for duo in nltk.pos_tag(tokens):\n",
    "# #         if duo[1] =='JJ': # adjectives\n",
    "# #             print(duo)           \n",
    "#     return [x[0] for x in nltk.pos_tag(tokens) if x[1]=='JJ']\n",
    "    tokens = TokenizeText(text)          \n",
    "    return [x[0] for x in nltk.pos_tag(tokens) if x[1] in t]\n",
    "    \n",
    "def GetAdjectivesFromText(text):\n",
    "    text = CleanText(text)\n",
    "    return helperGetWordsWithTokenType(text,['JJ'])\n",
    "\n",
    "def GetNounsFromText(text):\n",
    "    text = CleanText(text)\n",
    "    return helperGetWordsWithTokenType(text,['NN','NNS'])\n",
    "\n",
    "def GetVerbssFromText(text):\n",
    "    text = CleanText(text)\n",
    "    # Verbs are tricky... we have to add a 'to' before every word in the text, so we can convert words to verbs\n",
    "    # this will return any words that can be interpreted as a verb even if not used in the text that way.\n",
    "    # it's difficult to know by the text alone if a word is a verb or not, so this will force it to a verb.\n",
    "    \n",
    "    tokens = TokenizeText(text)       \n",
    "    words = [ 'to '+ x for x in tokens]\n",
    "#     print(' '.join(words))\n",
    "    return helperGetWordsWithTokenType(' '.join(words),['VBZ','VB'])\n",
    "\n",
    "def GetWordPairs(text):\n",
    "    text = CleanText(text)\n",
    "    tokens = TokenizeText(text)\n",
    "    \n",
    "    #we need to create a new array with pairs of the words in the tokens array.\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(0,len(tokens)-1,1):\n",
    "        firstWord = tokens[i]\n",
    "        secondWord = tokens[i+1]\n",
    "        pairs.append(set([firstWord,secondWord]))\n",
    "    #     print(set([firstWord,secondWord]))\n",
    "#     print(pairs)\n",
    "    return pairs\n",
    "\n",
    "def GetWordTriplets(text):\n",
    "    text = CleanText(text)\n",
    "    tokens = TokenizeText(text)\n",
    "    \n",
    "    #we need to create a new array with pairs of the words in the tokens array.\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(0,len(tokens)-2,1):\n",
    "        firstWord = tokens[i]\n",
    "        secondWord = tokens[i+1]\n",
    "        thirdWord = tokens[i+2]\n",
    "        pairs.append(set([firstWord,secondWord,thirdWord]))\n",
    "    #     print(set([firstWord,secondWord]))\n",
    "#     print(pairs)\n",
    "    return pairs\n",
    "\n",
    "from collections import defaultdict\n",
    "def count_frequency(word_list):\n",
    "    \"\"\" Function input: list object contains strings of individual words.\n",
    "        Function output: defaultdict() object containing {word, frequency} pairs. \"\"\"\n",
    "\n",
    "    freq_counts = defaultdict(int)\n",
    "    \n",
    "    for word in word_list:\n",
    "        freq_counts[word] += 1\n",
    "\n",
    "    return freq_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is', 'this'},\n",
       " {'is', 'my'},\n",
       " {'hate', 'my'},\n",
       " {'hate', 'text'},\n",
       " {'it', 'text'},\n",
       " {'includes', 'it'},\n",
       " {'commas', 'includes'},\n",
       " {'commas', 'question'},\n",
       " {'marks', 'question'},\n",
       " {'dog', 'marks'},\n",
       " {'and', 'dog'},\n",
       " {'and', 'other'},\n",
       " {'other', 'stuff'},\n",
       " {'also', 'stuff'},\n",
       " {'also', 'u'},\n",
       " {'s', 'u'},\n",
       " {'s', 'would'},\n",
       " {'not', 'would'},\n",
       " {'it', 'not'},\n",
       " {'be', 'it'},\n",
       " {'be', 'great'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GetVerbssFromText(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")\n",
    "# GetAdjectivesFromText(\"This is my text. It includes commas, question marks? and other stuff. Also U.S..\".lower())\n",
    "# #     print(duo[1])\n",
    "# # tokens\n",
    "# GetWordsAndTheirTags(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")\n",
    "\n",
    "# text = CleanText(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")\n",
    "# tokens = TokenizeText(text)  \n",
    "\n",
    "# pairs = []\n",
    "# for i in range(0,len(tokens)-1,1):\n",
    "#     firstWord = tokens[i]\n",
    "#     secondWord = tokens[i+1]\n",
    "#     pairs.append(set([firstWord,secondWord]))\n",
    "# #     print(set([firstWord,secondWord]))\n",
    "# print(pairs)\n",
    "# # tokens.rotate(1)\n",
    "GetWordPairs(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to tweak pandas data frames.\n",
    "def AddAdjectiveNounsVerbsToDF(df, textColumn):\n",
    "    df = df.copy()\n",
    "#     amzn_df['text_adjectives'] =amzn_df['review_text'].apply(lambda x: GetAdjectivesFromText(str(x).lower()))\n",
    "#     amzn_df['text_nouns'] =amzn_df['review_text'].apply(lambda x: GetNounsFromText(str(x).lower()))\n",
    "#     amzn_df['text_verbs'] =amzn_df['review_text'].apply(lambda x: GetVerbssFromText(str(x).lower()))\n",
    "    df['text_adjectives'] =df[textColumn].apply(lambda x: GetAdjectivesFromText(str(x).lower()))\n",
    "    df['text_adjectives'] = df['text_adjectives'].apply(lambda row: set([  x for x in row if(len(x) >1)]) )\n",
    "    \n",
    "    df['text_nouns'] =df[textColumn].apply(lambda x: GetNounsFromText(str(x).lower()))\n",
    "    df['text_nouns'] = df['text_nouns'].apply(lambda row: set([  x for x in row if(len(x) >1)]) )\n",
    "    \n",
    "    df['text_verbs'] =df[textColumn].apply(lambda x: GetVerbssFromText(str(x).lower()))\n",
    "    df['text_verbs'] = df['text_verbs'].apply(lambda row: set([  x for x in row if(len(x) >1)]) )\n",
    "    \n",
    "    # create word pairs.\n",
    "    df['text_pairs'] = df[textColumn].apply(lambda row: GetWordPairs(row))\n",
    "    df['text_triplets'] = df[textColumn].apply(lambda row: GetWordTriplets(row))\n",
    "    return df\n",
    "\n",
    "def GetDataframeOfWords(pandasdf, textColumn):\n",
    "#     pandasdf['words'] = CreateListForColumn(pandasdf, textColumn)\n",
    "    pandasdf['words']=pandasdf[textColumn]\n",
    "    wordArray = pandasdf[pandasdf['words'].map(lambda d: len(d)) > 0]['words'].values\n",
    "    words = []\n",
    "    for wordlist in wordArray:\n",
    "        words.extend(wordlist)\n",
    "    wordDictionary = count_frequency(words)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(wordDictionary, orient='index',\n",
    "                       columns=['count']).reset_index()\n",
    "    df = df.rename(columns={\"index\": \"word\"})\n",
    "    df = df.sort_values(by=['count'], ascending=False)\n",
    "    \n",
    "    totalWords = df['count'].sum()\n",
    "    df['usage'] = df['count']/totalWords\n",
    "#     df = df.set_index('word')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>text_adjectives</th>\n",
       "      <th>text_nouns</th>\n",
       "      <th>text_verbs</th>\n",
       "      <th>text_pairs</th>\n",
       "      <th>text_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Airpods Pro deliver😎</td>\n",
       "      <td>This airpods pro do exactly what apple said th...</td>\n",
       "      <td>{new, different, many}</td>\n",
       "      <td>{resistant, money, design, thats, tax, noise, ...</td>\n",
       "      <td>{ear, like, correctly, worth, design, buds, do...</td>\n",
       "      <td>[{this, airpods}, {pro, airpods}, {do, pro}, {...</td>\n",
       "      <td>[{pro, this, airpods}, {do, pro, airpods}, {do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>List of Features/Changes compared to Airpods (v2)</td>\n",
       "      <td>Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...</td>\n",
       "      <td>{battery, social, ear, old, replacement, rough...</td>\n",
       "      <td>{anytime, piece, lows, quality, pair, hours, p...</td>\n",
       "      <td>{go, anytime, piece, forward, like, quality, p...</td>\n",
       "      <td>[{iphone, like}, {11, iphone}, {11, pro}, {mac...</td>\n",
       "      <td>[{11, iphone, like}, {11, iphone, pro}, {macbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Cool but expensive</td>\n",
       "      <td>First review yeh heard about these excited but...</td>\n",
       "      <td>{excited}</td>\n",
       "      <td>{review, dollars, airpods}</td>\n",
       "      <td>{review, first, get, heard, yeh, like, less}</td>\n",
       "      <td>[{review, first}, {review, yeh}, {yeh, heard},...</td>\n",
       "      <td>[{review, yeh, first}, {review, yeh, heard}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Lit</td>\n",
       "      <td>They fire</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{fire}</td>\n",
       "      <td>[{fire, they}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Saved my marriage</td>\n",
       "      <td>With the new transparency mode, I can listen t...</td>\n",
       "      <td>{new}</td>\n",
       "      <td>{transparency, street, boys, music, tim, cook,...</td>\n",
       "      <td>{transparency, be, street, listen, ran, boys, ...</td>\n",
       "      <td>[{the, with}, {new, the}, {transparency, new},...</td>\n",
       "      <td>[{new, the, with}, {transparency, new, the}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  ProductName  review_rating  verified_purchase review_date  \\\n",
       "0        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "1        Apple  AirPods Pro              4                  0  2019-10-30   \n",
       "2        Apple  AirPods Pro              3                  0  2019-10-30   \n",
       "3        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "4        Apple  AirPods Pro              5                  1  2019-10-31   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                               Airpods Pro deliver😎   \n",
       "1  List of Features/Changes compared to Airpods (v2)   \n",
       "2                                 Cool but expensive   \n",
       "3                                                Lit   \n",
       "4                                  Saved my marriage   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This airpods pro do exactly what apple said th...   \n",
       "1  Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...   \n",
       "2  First review yeh heard about these excited but...   \n",
       "3                                          They fire   \n",
       "4  With the new transparency mode, I can listen t...   \n",
       "\n",
       "                                     text_adjectives  \\\n",
       "0                             {new, different, many}   \n",
       "1  {battery, social, ear, old, replacement, rough...   \n",
       "2                                          {excited}   \n",
       "3                                                 {}   \n",
       "4                                              {new}   \n",
       "\n",
       "                                          text_nouns  \\\n",
       "0  {resistant, money, design, thats, tax, noise, ...   \n",
       "1  {anytime, piece, lows, quality, pair, hours, p...   \n",
       "2                         {review, dollars, airpods}   \n",
       "3                                                 {}   \n",
       "4  {transparency, street, boys, music, tim, cook,...   \n",
       "\n",
       "                                          text_verbs  \\\n",
       "0  {ear, like, correctly, worth, design, buds, do...   \n",
       "1  {go, anytime, piece, forward, like, quality, p...   \n",
       "2       {review, first, get, heard, yeh, like, less}   \n",
       "3                                             {fire}   \n",
       "4  {transparency, be, street, listen, ran, boys, ...   \n",
       "\n",
       "                                          text_pairs  \\\n",
       "0  [{this, airpods}, {pro, airpods}, {do, pro}, {...   \n",
       "1  [{iphone, like}, {11, iphone}, {11, pro}, {mac...   \n",
       "2  [{review, first}, {review, yeh}, {yeh, heard},...   \n",
       "3                                     [{fire, they}]   \n",
       "4  [{the, with}, {new, the}, {transparency, new},...   \n",
       "\n",
       "                                       text_triplets  \n",
       "0  [{pro, this, airpods}, {do, pro, airpods}, {do...  \n",
       "1  [{11, iphone, like}, {11, iphone, pro}, {macbo...  \n",
       "2  [{review, yeh, first}, {review, yeh, heard}, {...  \n",
       "3                                                 []  \n",
       "4  [{new, the, with}, {transparency, new, the}, {...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_df = GetAmazonTextReviewsDf()\n",
    "amzn_df = AddAdjectiveNounsVerbsToDF(amzn_df,'review_text')\n",
    "amzn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>text_adjectives</th>\n",
       "      <th>text_nouns</th>\n",
       "      <th>text_verbs</th>\n",
       "      <th>text_pairs</th>\n",
       "      <th>text_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Airpods Pro deliver😎</td>\n",
       "      <td>This airpods pro do exactly what apple said th...</td>\n",
       "      <td>{new, different, many}</td>\n",
       "      <td>{resistant, money, design, thats, tax, noise, ...</td>\n",
       "      <td>{ear, like, correctly, worth, design, buds, do...</td>\n",
       "      <td>[{this, airpods}, {pro, airpods}, {do, pro}, {...</td>\n",
       "      <td>[{pro, this, airpods}, {do, pro, airpods}, {do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>List of Features/Changes compared to Airpods (v2)</td>\n",
       "      <td>Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...</td>\n",
       "      <td>{battery, social, ear, old, replacement, rough...</td>\n",
       "      <td>{anytime, piece, lows, quality, pair, hours, p...</td>\n",
       "      <td>{go, anytime, piece, forward, like, quality, p...</td>\n",
       "      <td>[{iphone, like}, {11, iphone}, {11, pro}, {mac...</td>\n",
       "      <td>[{11, iphone, like}, {11, iphone, pro}, {macbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Cool but expensive</td>\n",
       "      <td>First review yeh heard about these excited but...</td>\n",
       "      <td>{excited}</td>\n",
       "      <td>{review, dollars, airpods}</td>\n",
       "      <td>{review, first, get, heard, yeh, like, less}</td>\n",
       "      <td>[{review, first}, {review, yeh}, {yeh, heard},...</td>\n",
       "      <td>[{review, yeh, first}, {review, yeh, heard}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Lit</td>\n",
       "      <td>They fire</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{fire}</td>\n",
       "      <td>[{fire, they}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Saved my marriage</td>\n",
       "      <td>With the new transparency mode, I can listen t...</td>\n",
       "      <td>{new}</td>\n",
       "      <td>{transparency, street, boys, music, tim, cook,...</td>\n",
       "      <td>{transparency, be, street, listen, ran, boys, ...</td>\n",
       "      <td>[{the, with}, {new, the}, {transparency, new},...</td>\n",
       "      <td>[{new, the, with}, {transparency, new, the}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  ProductName  review_rating  verified_purchase review_date  \\\n",
       "0        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "1        Apple  AirPods Pro              4                  0  2019-10-30   \n",
       "2        Apple  AirPods Pro              3                  0  2019-10-30   \n",
       "3        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "4        Apple  AirPods Pro              5                  1  2019-10-31   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                               Airpods Pro deliver😎   \n",
       "1  List of Features/Changes compared to Airpods (v2)   \n",
       "2                                 Cool but expensive   \n",
       "3                                                Lit   \n",
       "4                                  Saved my marriage   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This airpods pro do exactly what apple said th...   \n",
       "1  Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...   \n",
       "2  First review yeh heard about these excited but...   \n",
       "3                                          They fire   \n",
       "4  With the new transparency mode, I can listen t...   \n",
       "\n",
       "                                     text_adjectives  \\\n",
       "0                             {new, different, many}   \n",
       "1  {battery, social, ear, old, replacement, rough...   \n",
       "2                                          {excited}   \n",
       "3                                                 {}   \n",
       "4                                              {new}   \n",
       "\n",
       "                                          text_nouns  \\\n",
       "0  {resistant, money, design, thats, tax, noise, ...   \n",
       "1  {anytime, piece, lows, quality, pair, hours, p...   \n",
       "2                         {review, dollars, airpods}   \n",
       "3                                                 {}   \n",
       "4  {transparency, street, boys, music, tim, cook,...   \n",
       "\n",
       "                                          text_verbs  \\\n",
       "0  {ear, like, correctly, worth, design, buds, do...   \n",
       "1  {go, anytime, piece, forward, like, quality, p...   \n",
       "2       {review, first, get, heard, yeh, like, less}   \n",
       "3                                             {fire}   \n",
       "4  {transparency, be, street, listen, ran, boys, ...   \n",
       "\n",
       "                                          text_pairs  \\\n",
       "0  [{this, airpods}, {pro, airpods}, {do, pro}, {...   \n",
       "1  [{iphone, like}, {11, iphone}, {11, pro}, {mac...   \n",
       "2  [{review, first}, {review, yeh}, {yeh, heard},...   \n",
       "3                                     [{fire, they}]   \n",
       "4  [{the, with}, {new, the}, {transparency, new},...   \n",
       "\n",
       "                                       text_triplets  \n",
       "0  [{pro, this, airpods}, {do, pro, airpods}, {do...  \n",
       "1  [{11, iphone, like}, {11, iphone, pro}, {macbo...  \n",
       "2  [{review, yeh, first}, {review, yeh, heard}, {...  \n",
       "3                                                 []  \n",
       "4  [{new, the, with}, {transparency, new, the}, {...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mikulskibartosz.name/how-to-split-a-list-inside-a-dataframe-cell-into-rows-in-pandas/\n",
    "\n",
    "# GetDataframeOfWords(amzn_df,'text_adjectives')\n",
    "# GetDataframeOfWords(amzn_df,'text_verbs')\n",
    "\n",
    "\n",
    "# GetDataframeOfWords(amzn_df[:50],'text_pairs')\n",
    "# from collections import Counter\n",
    "# Counter(amzn_df[:50]['text_pairs'])\n",
    "\n",
    "# amzn_df[:50]['text_pairs'].value_counts()\n",
    "\n",
    "# data = amzn_df[40:50][['review_date','verified_purchase','text_pairs']]\n",
    "# data = amzn_df[40:50]\n",
    "\n",
    "# data['text_pairs']#.apply(lambda x: x[0])\n",
    "\n",
    "# data=data.reset_index()\n",
    "# # data.where(data['text_pairs'])\n",
    "\n",
    "# ### This is a bit tricky what this is doing...###\n",
    "# #  we create a new temp column, which is where we get the values from that we'll be working with.\n",
    "# #  take the column and dumping that into it's own data frame, which makes a bunch of columns. (from array to df)\n",
    "# #  merge the the new dataframe with all of our many columns back into the original data frame with columns we want to keep.\n",
    "# #  we remove the temp column. This temp column would melt into our final column we are making...\n",
    "# #     the issue I had was without removing the column I could get pairs merged with other pairs, wo they ended up being \n",
    "# #     sets of 3+ merged with who knows what, which isn't what I wanted.\n",
    "# #  there is a variable column that's created in this process which we can remove.\n",
    "# data[\"tempPairs\"] = data[\"text_pairs\"]\n",
    "# data = data['text_pairs'].apply(pd.Series)\\\n",
    "#     .merge(data, right_index = True, left_index = True) \\\n",
    "#     .drop([\"tempPairs\"], axis = 1)\\\n",
    "#     .drop([\"text_pairs\"], axis = 1)\\\n",
    "#     .melt(id_vars = ['review_date', 'verified_purchase'], value_name = \"pairs\") \\\n",
    "#     .drop(\"variable\", axis = 1)\n",
    "\n",
    "def GetReviewPairsCounts(df, pairsColumn, columnstoKeep=['review_date', 'verified_purchase']):\n",
    "    data = df.copy()\n",
    "    data[\"tempPairs\"] = data[pairsColumn]\n",
    "    data = data[pairsColumn].apply(pd.Series)\\\n",
    "    .merge(data, right_index = True, left_index = True) \\\n",
    "    .drop([\"tempPairs\"], axis = 1)\\\n",
    "    .drop([pairsColumn], axis = 1)\\\n",
    "    .melt(id_vars =columnstoKeep, value_name = \"pairs\") \\\n",
    "    .drop(\"variable\", axis = 1).dropna()\n",
    "    \n",
    "    # count should be a ratio of the current elem/total sets. NOTE: can't really count them here...value too small.\n",
    "    totalReview= len(df['verified_purchase'])\n",
    "    data['count'] = data['verified_purchase'].apply(lambda x: 1/totalReview)\n",
    "#     data['count'] = data['verified_purchase'].apply(lambda x: 1)\n",
    "    \n",
    "    # we can't group by a set, so we need to make it a string like object, so we can hash it.\n",
    "    data['pairs_hashable'] = data['pairs'].apply(lambda x: repr(x))\n",
    "    \n",
    "#     countsdf = data.pairs.value_counts().reset_index().rename(columns={'pairs':'total','index':'pairs'})\n",
    "    \n",
    "#     pd.merge(data,countsdf, on='pairs', )\n",
    "    \n",
    "    return data\n",
    "\n",
    "def CreateFullDFOfProductsAndWordPairs(amzn_Df):\n",
    "    ### this function will try to keep the product name field and format a dataframe that we can easily parse\n",
    "    final_df = None\n",
    "    for elem in amzn_df['ProductName'].unique():\n",
    "        \n",
    "        df = amzn_df.where(amzn_df['ProductName'] == elem).dropna()\n",
    "        df = df[['review_date','verified_purchase','text_pairs']]\n",
    "        df = GetReviewPairsCounts(df, 'text_pairs',['review_date', 'verified_purchase'] )\n",
    "        df['ProductName'] = df['pairs'].apply(lambda x: elem)\n",
    "        if final_df is None:\n",
    "            final_df=df\n",
    "        else:\n",
    "            final_df = pd.concat([final_df,df])\n",
    "            \n",
    "    return final_df\n",
    "\n",
    "# data = amzn_df[['review_date','verified_purchase','text_pairs']]\n",
    "# data = GetReviewPairsCounts(data, 'text_pairs',['review_date', 'verified_purchase'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will cover analysis of only single words found in the list. We will take a top down approach.<br><br>\n",
    "<ul>\n",
    "    <li> high reviews are above 3 and low reviews are less than 3, what are the unique words between the high and low?</li>\n",
    "    <li> what are the unique words between the purchased and not purchased?</li>\n",
    "    <li> what are the unique words between the products?</li>\n",
    "\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>text_adjectives</th>\n",
       "      <th>text_nouns</th>\n",
       "      <th>text_verbs</th>\n",
       "      <th>text_pairs</th>\n",
       "      <th>text_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Airpods Pro deliver😎</td>\n",
       "      <td>This airpods pro do exactly what apple said th...</td>\n",
       "      <td>{new, different, many}</td>\n",
       "      <td>{resistant, money, design, thats, tax, noise, ...</td>\n",
       "      <td>{ear, like, correctly, worth, design, buds, do...</td>\n",
       "      <td>[{this, airpods}, {pro, airpods}, {do, pro}, {...</td>\n",
       "      <td>[{pro, this, airpods}, {do, pro, airpods}, {do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>List of Features/Changes compared to Airpods (v2)</td>\n",
       "      <td>Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...</td>\n",
       "      <td>{battery, social, ear, old, replacement, rough...</td>\n",
       "      <td>{anytime, piece, lows, quality, pair, hours, p...</td>\n",
       "      <td>{go, anytime, piece, forward, like, quality, p...</td>\n",
       "      <td>[{iphone, like}, {11, iphone}, {11, pro}, {mac...</td>\n",
       "      <td>[{11, iphone, like}, {11, iphone, pro}, {macbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Cool but expensive</td>\n",
       "      <td>First review yeh heard about these excited but...</td>\n",
       "      <td>{excited}</td>\n",
       "      <td>{review, dollars, airpods}</td>\n",
       "      <td>{review, first, get, heard, yeh, like, less}</td>\n",
       "      <td>[{review, first}, {review, yeh}, {yeh, heard},...</td>\n",
       "      <td>[{review, yeh, first}, {review, yeh, heard}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Lit</td>\n",
       "      <td>They fire</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{fire}</td>\n",
       "      <td>[{fire, they}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Saved my marriage</td>\n",
       "      <td>With the new transparency mode, I can listen t...</td>\n",
       "      <td>{new}</td>\n",
       "      <td>{transparency, street, boys, music, tim, cook,...</td>\n",
       "      <td>{transparency, be, street, listen, ran, boys, ...</td>\n",
       "      <td>[{the, with}, {new, the}, {transparency, new},...</td>\n",
       "      <td>[{new, the, with}, {transparency, new, the}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  ProductName  review_rating  verified_purchase review_date  \\\n",
       "0        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "1        Apple  AirPods Pro              4                  0  2019-10-30   \n",
       "2        Apple  AirPods Pro              3                  0  2019-10-30   \n",
       "3        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "4        Apple  AirPods Pro              5                  1  2019-10-31   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                               Airpods Pro deliver😎   \n",
       "1  List of Features/Changes compared to Airpods (v2)   \n",
       "2                                 Cool but expensive   \n",
       "3                                                Lit   \n",
       "4                                  Saved my marriage   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This airpods pro do exactly what apple said th...   \n",
       "1  Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...   \n",
       "2  First review yeh heard about these excited but...   \n",
       "3                                          They fire   \n",
       "4  With the new transparency mode, I can listen t...   \n",
       "\n",
       "                                     text_adjectives  \\\n",
       "0                             {new, different, many}   \n",
       "1  {battery, social, ear, old, replacement, rough...   \n",
       "2                                          {excited}   \n",
       "3                                                 {}   \n",
       "4                                              {new}   \n",
       "\n",
       "                                          text_nouns  \\\n",
       "0  {resistant, money, design, thats, tax, noise, ...   \n",
       "1  {anytime, piece, lows, quality, pair, hours, p...   \n",
       "2                         {review, dollars, airpods}   \n",
       "3                                                 {}   \n",
       "4  {transparency, street, boys, music, tim, cook,...   \n",
       "\n",
       "                                          text_verbs  \\\n",
       "0  {ear, like, correctly, worth, design, buds, do...   \n",
       "1  {go, anytime, piece, forward, like, quality, p...   \n",
       "2       {review, first, get, heard, yeh, like, less}   \n",
       "3                                             {fire}   \n",
       "4  {transparency, be, street, listen, ran, boys, ...   \n",
       "\n",
       "                                          text_pairs  \\\n",
       "0  [{this, airpods}, {pro, airpods}, {do, pro}, {...   \n",
       "1  [{iphone, like}, {11, iphone}, {11, pro}, {mac...   \n",
       "2  [{review, first}, {review, yeh}, {yeh, heard},...   \n",
       "3                                     [{fire, they}]   \n",
       "4  [{the, with}, {new, the}, {transparency, new},...   \n",
       "\n",
       "                                       text_triplets  \n",
       "0  [{pro, this, airpods}, {do, pro, airpods}, {do...  \n",
       "1  [{11, iphone, like}, {11, iphone, pro}, {macbo...  \n",
       "2  [{review, yeh, first}, {review, yeh, heard}, {...  \n",
       "3                                                 []  \n",
       "4  [{new, the, with}, {transparency, new, the}, {...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word pairs entire list of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a data frame of all the reviews. We want to see overall what are the different words between the purchased and not purchased sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>pairs</th>\n",
       "      <th>count</th>\n",
       "      <th>pairs_hashable</th>\n",
       "      <th>ProductName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{this, airpods}</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>{'this', 'airpods'}</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{iphone, like}</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>{'iphone', 'like'}</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{review, first}</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>{'review', 'first'}</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{fire, they}</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>{'fire', 'they'}</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{the, with}</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>{'the', 'with'}</td>\n",
       "      <td>AirPods Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_date  verified_purchase            pairs     count  \\\n",
       "0  2019-10-30                0.0  {this, airpods}  0.000242   \n",
       "1  2019-10-30                0.0   {iphone, like}  0.000242   \n",
       "2  2019-10-30                0.0  {review, first}  0.000242   \n",
       "3  2019-10-30                0.0     {fire, they}  0.000242   \n",
       "4  2019-10-31                1.0      {the, with}  0.000242   \n",
       "\n",
       "        pairs_hashable  ProductName  \n",
       "0  {'this', 'airpods'}  AirPods Pro  \n",
       "1   {'iphone', 'like'}  AirPods Pro  \n",
       "2  {'review', 'first'}  AirPods Pro  \n",
       "3     {'fire', 'they'}  AirPods Pro  \n",
       "4      {'the', 'with'}  AirPods Pro  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "wordPairsAllReviews_df= CreateFullDFOfProductsAndWordPairs(amzn_df)\n",
    "wordPairsAllReviews_df.head()\n",
    "# We want ProductName, Manufacturer, pairs_hashable, sum\n",
    "# highRatings = data.where(data['review_rating'] >= 4).dropna()\n",
    "# lowRatings = data.where(data['review_rating'] <= 2).dropna()\n",
    "# lowRatings\n",
    "# lowRatings.groupby(['verified_purchase','ProductName','Manufacturer','pairs_hashable']).sum()\n",
    "\n",
    "# data[['pairs_hashable','count']].groupby('pairs_hashable').sum()\n",
    "\n",
    "\n",
    "# data[['pairs','count']].groupby('pairs').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallPopularwords= wordPairsAllReviews_df.groupby(['pairs_hashable','verified_purchase']).sum().reset_index()\n",
    "\n",
    "\n",
    "overallPopularwords_notPurchased = overallPopularwords.where(overallPopularwords['verified_purchase'] == 0).dropna()\n",
    "overallPopularwords_notPurchased = overallPopularwords_notPurchased.sort_values(by=['count'],ascending =False).reset_index().drop(columns=['index'])\n",
    "\n",
    "overallPopularwords_purchased = overallPopularwords.where(overallPopularwords['verified_purchase'] == 1).dropna()\n",
    "overallPopularwords_purchased = overallPopularwords_purchased.sort_values(by=['count'],ascending =False).reset_index().drop(columns=['index'])\n",
    "\n",
    "# now we have two datasets one with purchased the other not purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs_hashable</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'of', 'the'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'the', 'on'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'i', 'have'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'the', 'with'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'sound', 'the'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'the', 'in'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'sound', 'quality'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'i', 'm'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'the', 'and'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'s', 'it'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pairs_hashable  verified_purchase     count\n",
       "0         {'of', 'the'}                0.0  0.819273\n",
       "1         {'the', 'on'}                0.0  0.625983\n",
       "2         {'i', 'have'}                0.0  0.561268\n",
       "3       {'the', 'with'}                0.0  0.546574\n",
       "4      {'sound', 'the'}                0.0  0.531527\n",
       "5         {'the', 'in'}                0.0  0.522295\n",
       "6  {'sound', 'quality'}                0.0  0.508188\n",
       "7            {'i', 'm'}                0.0  0.498588\n",
       "8        {'the', 'and'}                0.0  0.487143\n",
       "9           {'s', 'it'}                0.0  0.475692"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overallPopularwords_notPurchased.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs_hashable</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'sound', 'quality'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.910665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'sound', 'the'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.819174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'i', 'have'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.738156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'of', 'the'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.697762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'the', 'in'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.507372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'the', 'and'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.476486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'i', 'm'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'battery', 'life'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.355736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'the', 'on'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.354728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'t', 'don'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.241906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pairs_hashable  verified_purchase     count\n",
       "0  {'sound', 'quality'}                1.0  1.910665\n",
       "1      {'sound', 'the'}                1.0  1.819174\n",
       "2         {'i', 'have'}                1.0  1.738156\n",
       "3         {'of', 'the'}                1.0  1.697762\n",
       "4         {'the', 'in'}                1.0  1.507372\n",
       "5        {'the', 'and'}                1.0  1.476486\n",
       "6            {'i', 'm'}                1.0  1.414304\n",
       "7   {'battery', 'life'}                1.0  1.355736\n",
       "8         {'the', 'on'}                1.0  1.354728\n",
       "9          {'t', 'don'}                1.0  1.241906"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overallPopularwords_purchased.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to merge the two verified _purchase lists into a data frame. We don't want pairs that appear in the other list.\n",
    "# we can say from the top 20 words, which ones are unique?\n",
    "\n",
    "# we can take the intersection between two lists then remove those words found in the intersection from those of both lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs_hashable</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'sound', 'quality'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.910665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'sound', 'the'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.819174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'i', 'have'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.738156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'of', 'the'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.697762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'the', 'in'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.507372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'the', 'and'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.476486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'i', 'm'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'battery', 'life'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.355736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'the', 'on'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.354728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'t', 'don'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.241906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'the', 'for'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.233958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'the', 'with'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.233271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'are', 'they'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.231701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'s', 'it'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.199792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'i', 've'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.166317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'i', 'and'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.164156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'are', 'these'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.038982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'you', 'if'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.023525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'is', 'quality'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.008503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'to', 'the'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'was', 'i'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'cancellation', 'noise'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'the', 'case'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'i', 'can'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'have', 'to'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'the', 'noise'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'my', 'in'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'cancelling', 'noise'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'but', 'i'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'i', 'am'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168041</th>\n",
       "      <td>{'huuuuuge', 'step'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168042</th>\n",
       "      <td>{'than', 'wear'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168043</th>\n",
       "      <td>{'thanks', 'foolish'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168044</th>\n",
       "      <td>{'thanks', 'evaluation'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168045</th>\n",
       "      <td>{'coffee', 'as'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168046</th>\n",
       "      <td>{'coffee', 'long'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168047</th>\n",
       "      <td>{'of', 'feature'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168048</th>\n",
       "      <td>{'thanks', 'bye'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168049</th>\n",
       "      <td>{'thanks', 'avoided'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168050</th>\n",
       "      <td>{'husband', 'snoring'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168051</th>\n",
       "      <td>{'of', 'feels'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168052</th>\n",
       "      <td>{'coffee', 'the'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168053</th>\n",
       "      <td>{'husband', 'said'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168054</th>\n",
       "      <td>{'thanks', 'all'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168055</th>\n",
       "      <td>{'thanks', 'accomplished'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168056</th>\n",
       "      <td>{'thanking', 'me'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168057</th>\n",
       "      <td>{'thanking', 'keeps'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168058</th>\n",
       "      <td>{'thankfully', 'window'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168059</th>\n",
       "      <td>{'of', 'filtering'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168060</th>\n",
       "      <td>{'thank', 'u'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168061</th>\n",
       "      <td>{'husband', 'borrowed'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168062</th>\n",
       "      <td>{'thank', 'perfect'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168063</th>\n",
       "      <td>{'thank', 'party'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168064</th>\n",
       "      <td>{'colleague', 'and'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168065</th>\n",
       "      <td>{'thank', 'about'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168066</th>\n",
       "      <td>{'thank', '2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168067</th>\n",
       "      <td>{'than', 'would'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168068</th>\n",
       "      <td>{'collect', 'they'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168069</th>\n",
       "      <td>{'collection', 'and'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168070</th>\n",
       "      <td>{'charged', '58'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168071 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pairs_hashable  verified_purchase     count\n",
       "0             {'sound', 'quality'}                1.0  1.910665\n",
       "1                 {'sound', 'the'}                1.0  1.819174\n",
       "2                    {'i', 'have'}                1.0  1.738156\n",
       "3                    {'of', 'the'}                1.0  1.697762\n",
       "4                    {'the', 'in'}                1.0  1.507372\n",
       "5                   {'the', 'and'}                1.0  1.476486\n",
       "6                       {'i', 'm'}                1.0  1.414304\n",
       "7              {'battery', 'life'}                1.0  1.355736\n",
       "8                    {'the', 'on'}                1.0  1.354728\n",
       "9                     {'t', 'don'}                1.0  1.241906\n",
       "10                  {'the', 'for'}                1.0  1.233958\n",
       "11                 {'the', 'with'}                1.0  1.233271\n",
       "12                 {'are', 'they'}                1.0  1.231701\n",
       "13                     {'s', 'it'}                1.0  1.199792\n",
       "14                     {'i', 've'}                1.0  1.166317\n",
       "15                    {'i', 'and'}                1.0  1.164156\n",
       "16                {'are', 'these'}                1.0  1.038982\n",
       "17                   {'you', 'if'}                1.0  1.023525\n",
       "18               {'is', 'quality'}                1.0  1.008503\n",
       "19                   {'to', 'the'}                1.0  0.978738\n",
       "20                    {'was', 'i'}                1.0  0.976594\n",
       "21       {'cancellation', 'noise'}                1.0  0.940980\n",
       "22                 {'the', 'case'}                1.0  0.909257\n",
       "23                    {'i', 'can'}                1.0  0.901320\n",
       "24                  {'have', 'to'}                1.0  0.899781\n",
       "25                {'the', 'noise'}                1.0  0.890259\n",
       "26                    {'my', 'in'}                1.0  0.836708\n",
       "27         {'cancelling', 'noise'}                1.0  0.822343\n",
       "28                    {'but', 'i'}                1.0  0.796298\n",
       "29                     {'i', 'am'}                1.0  0.782345\n",
       "...                            ...                ...       ...\n",
       "168041        {'huuuuuge', 'step'}                1.0  0.000242\n",
       "168042            {'than', 'wear'}                1.0  0.000242\n",
       "168043       {'thanks', 'foolish'}                1.0  0.000242\n",
       "168044    {'thanks', 'evaluation'}                1.0  0.000242\n",
       "168045            {'coffee', 'as'}                1.0  0.000242\n",
       "168046          {'coffee', 'long'}                1.0  0.000242\n",
       "168047           {'of', 'feature'}                1.0  0.000242\n",
       "168048           {'thanks', 'bye'}                1.0  0.000242\n",
       "168049       {'thanks', 'avoided'}                1.0  0.000242\n",
       "168050      {'husband', 'snoring'}                1.0  0.000242\n",
       "168051             {'of', 'feels'}                1.0  0.000242\n",
       "168052           {'coffee', 'the'}                1.0  0.000242\n",
       "168053         {'husband', 'said'}                1.0  0.000242\n",
       "168054           {'thanks', 'all'}                1.0  0.000242\n",
       "168055  {'thanks', 'accomplished'}                1.0  0.000242\n",
       "168056          {'thanking', 'me'}                1.0  0.000242\n",
       "168057       {'thanking', 'keeps'}                1.0  0.000242\n",
       "168058    {'thankfully', 'window'}                1.0  0.000242\n",
       "168059         {'of', 'filtering'}                1.0  0.000242\n",
       "168060              {'thank', 'u'}                1.0  0.000242\n",
       "168061     {'husband', 'borrowed'}                1.0  0.000242\n",
       "168062        {'thank', 'perfect'}                1.0  0.000242\n",
       "168063          {'thank', 'party'}                1.0  0.000242\n",
       "168064        {'colleague', 'and'}                1.0  0.000242\n",
       "168065          {'thank', 'about'}                1.0  0.000242\n",
       "168066              {'thank', '2'}                1.0  0.000242\n",
       "168067           {'than', 'would'}                1.0  0.000242\n",
       "168068         {'collect', 'they'}                1.0  0.000242\n",
       "168069       {'collection', 'and'}                1.0  0.000242\n",
       "168070           {'charged', '58'}                1.0  0.000242\n",
       "\n",
       "[168071 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularWordPairs = data.groupby(['pairs_hashable','verified_purchase']).sum().reset_index()\n",
    "mostPopularWordPairsPurchased = mostPopularWordPairs.where(mostPopularWordPairs['verified_purchase'] == 1).dropna()\n",
    "mostPopularWordPairsPurchased.sort_values(by=['count'],ascending =False).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
