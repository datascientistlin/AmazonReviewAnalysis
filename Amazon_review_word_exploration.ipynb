{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't put any google trends data here since we are only exploring amazon reviews in this notebook.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def GetMergedAmazonDataFrames():\n",
    "#     files_to_use = [r'data\\AirPods Pro.csv', r'data\\Elite 75t.csv',r'data\\Free.csv',\n",
    "#                    r'data\\Galaxy Buds Plus.csv',r'data\\M-200.csv',r'data\\NC700.csv',\n",
    "#                    r'data\\Soundcore Liberty 2 Pro.csv',r'data\\Soundcore Liberty Air 2.csv',r'data\\Soundcore Life Q20.csv',\n",
    "#                    r'data\\WF-1000XM3.csv']\n",
    "    files_to_use = [r'data\\AirPods Pro.csv', r'data\\Elite 75t.csv',r'data\\Free.csv',\n",
    "                   r'data\\Galaxy Buds Plus.csv',r'data\\NC700.csv',\n",
    "                   r'data\\Soundcore Liberty 2 Pro.csv',r'data\\Soundcore Liberty Air 2.csv',r'data\\Soundcore Life Q20.csv',\n",
    "                   r'data\\WF-1000XM3.csv']\n",
    "    \n",
    "    amzn_df = pd.read_csv(files_to_use[0],  parse_dates=False)\n",
    "    for file in files_to_use[1:]:\n",
    "        df = pd.read_csv(file,  parse_dates=False)\n",
    "#         amzn_df = pd.merge(amzn_df, df, how='outer',on='review_date')\n",
    "        amzn_df = pd.concat([amzn_df,df],sort=False)\n",
    "        \n",
    "    amzn_df['review_date'] = pd.to_datetime(amzn_df['review_date'], format='%Y-%m-%d')\n",
    "    amzn_df = amzn_df[['Manufacturer', 'ProductName', 'review_rating', 'verified_purchase',\n",
    "       'review_date', 'review_title', 'review_text']]\n",
    "    return amzn_df\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def GetAmazonTextReviewsDf():\n",
    "    ### This function is used to prepare \n",
    "    #   the data frame to word and text analysis.. ####\n",
    "    amzn_df = GetMergedAmazonDataFrames()\n",
    "    columns = ['Manufacturer', 'ProductName', 'review_rating', 'verified_purchase',\n",
    "       'review_date', 'review_title', 'review_text']\n",
    "    \n",
    "    amzn_df=amzn_df[columns]\n",
    "    return amzn_df\n",
    "#     amzn_df['totalReviews'] =\n",
    "    \n",
    "def GetAmazonNumericalReviewsDf():\n",
    "    amzn_df = GetMergedAmazonDataFrames()\n",
    "    columns = ['Manufacturer', 'ProductName', 'review_rating', 'verified_purchase',\n",
    "       'review_date']\n",
    "    \n",
    "    amzn_df=amzn_df[columns]\n",
    "    # split into two data sets for purchased and not purchased.\n",
    "    amzn_purchased = amzn_df.where(amzn_df['verified_purchase']== 1).dropna()\n",
    "    amzn_notPurchased = amzn_df.where(amzn_df['verified_purchase']== 0).dropna()\n",
    "    \n",
    "    tempdf = None\n",
    "    for product in amzn_purchased['ProductName'].unique():\n",
    "        df = amzn_purchased.where(amzn_purchased['ProductName'] == product).dropna()\n",
    "        \n",
    "        manufacturer = df['Manufacturer'].unique()[0]\n",
    "        df= df[['review_rating','review_date']]\n",
    "        \n",
    "        dfCount = df\n",
    "        df = df.set_index('review_date').resample('W-SAT').mean().reset_index()#.agg(['mean','count']).reset_index()\n",
    "#         df['review_rating'] = df['review_rating'].fillna(0)\n",
    "        df['review_rating_norm'] = Normalize(df['review_rating'].fillna(df['review_rating'].mean()))\n",
    "        df['ProductName'] = df['review_rating'].apply(lambda x: product)\n",
    "        df['Manufacturer'] = df['review_rating'].apply(lambda x: manufacturer)\n",
    "        df['verified_purchase'] = df['review_rating'].apply(lambda x: '1')\n",
    "        df['count'] = dfCount[['review_rating','review_date']].set_index('review_date').resample('W-SAT').count().reset_index()['review_rating']\n",
    "#         print(df.head())\n",
    "        if tempdf is None:\n",
    "            tempdf = df\n",
    "        else:\n",
    "            tempdf = pd.concat([tempdf, df])\n",
    "            \n",
    "    \n",
    "    for product in amzn_notPurchased['ProductName'].unique():\n",
    "        df = amzn_notPurchased.where(amzn_notPurchased['ProductName'] == product).dropna()\n",
    "        \n",
    "        manufacturer = df['Manufacturer'].unique()[0]\n",
    "        df= df[['review_rating','review_date']]\n",
    "        \n",
    "        dfCount = df\n",
    "        \n",
    "        \n",
    "        df = df.set_index('review_date').resample('W-SAT').mean().reset_index()#.agg(['mean','count']).reset_index()\n",
    "#         df['review_rating'] = df['review_rating'].fillna(0)\n",
    "        df['review_rating_norm'] = Normalize(df['review_rating'].fillna(df['review_rating'].mean()))\n",
    "        df['ProductName'] = df['review_rating'].apply(lambda x: product)\n",
    "        df['Manufacturer'] = df['review_rating'].apply(lambda x: manufacturer)\n",
    "        df['verified_purchase'] = df['review_rating'].apply(lambda x: '0')\n",
    "        df['count'] = dfCount[['review_rating','review_date']].set_index('review_date').resample('W-SAT').count().reset_index()['review_rating']\n",
    "        \n",
    "#         print(df.head())\n",
    "        if tempdf is None:\n",
    "            tempdf = df\n",
    "        else:\n",
    "            tempdf = pd.concat([tempdf, df])\n",
    "            \n",
    "    return tempdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(array):\n",
    "    return array / np.linalg.norm(array, ord=1)\n",
    "    \n",
    "# Sav-golay filter for averaging.\n",
    "def savGolay(array, window = 9, order =7):\n",
    "    from scipy.ndimage import convolve1d\n",
    "    from scipy.signal import savgol_coeffs, savgol_filter\n",
    "    from scipy.signal._savitzky_golay import _polyder\n",
    "    return savgol_filter(array, window, order)\n",
    "   \n",
    "# Simple Moving Average used in financial data.\n",
    "def SMA(pandas_df_daily,columnName, dayWindowSize=20):\n",
    "    daily_close_df = pandas_df_daily[columnName].copy()\n",
    "    return daily_close_df.rolling(dayWindowSize).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for working with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AngryGamers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\AngryGamers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "\n",
    "def TokenizeText(text):\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#     text = \"This is my text. It includes commas, question marks? and other stuff. Also U.S..\".lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def GetWordsAndTheirTags(text):\n",
    "    text = CleanText(text)\n",
    "    tokens = TokenizeText(text)\n",
    "    return nltk.pos_tag(tokens)\n",
    "\n",
    "def CleanText(text):\n",
    "    text=str(text)\n",
    "    text= text.lower().replace(\"wouldn\\'t\",\"would not\")\n",
    "    return text\n",
    "def helperGetWordsWithTokenType(text, t):   \n",
    "# #     print(nltk.help.upenn_tagset('PRP$'))\n",
    "# #     print(text)\n",
    "#     text = CleanText(text)\n",
    "#     tokens = TokenizeText(text)\n",
    "# #     for duo in nltk.pos_tag(tokens):\n",
    "# #         if duo[1] =='JJ': # adjectives\n",
    "# #             print(duo)           \n",
    "#     return [x[0] for x in nltk.pos_tag(tokens) if x[1]=='JJ']\n",
    "    tokens = TokenizeText(text)          \n",
    "    return [x[0] for x in nltk.pos_tag(tokens) if x[1] in t]\n",
    "    \n",
    "def GetAdjectivesFromText(text):\n",
    "    text = CleanText(text)\n",
    "    return helperGetWordsWithTokenType(text,['JJ'])\n",
    "\n",
    "def GetNounsFromText(text):\n",
    "    text = CleanText(text)\n",
    "    return helperGetWordsWithTokenType(text,['NN','NNS'])\n",
    "\n",
    "def GetVerbssFromText(text):\n",
    "    text = CleanText(text)\n",
    "    # Verbs are tricky... we have to add a 'to' before every word in the text, so we can convert words to verbs\n",
    "    # this will return any words that can be interpreted as a verb even if not used in the text that way.\n",
    "    # it's difficult to know by the text alone if a word is a verb or not, so this will force it to a verb.\n",
    "    \n",
    "    tokens = TokenizeText(text)       \n",
    "    words = [ 'to '+ x for x in tokens]\n",
    "#     print(' '.join(words))\n",
    "    return helperGetWordsWithTokenType(' '.join(words),['VBZ','VB'])\n",
    "\n",
    "def GetWordPairs(text):\n",
    "    text = CleanText(text)\n",
    "    tokens = TokenizeText(text)\n",
    "    \n",
    "    #we need to create a new array with pairs of the words in the tokens array.\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(0,len(tokens)-1,1):\n",
    "        firstWord = tokens[i]\n",
    "        secondWord = tokens[i+1]\n",
    "        pairs.append(set([firstWord,secondWord]))\n",
    "    #     print(set([firstWord,secondWord]))\n",
    "#     print(pairs)\n",
    "    return pairs\n",
    "\n",
    "def GetWordTriplets(text):\n",
    "    text = CleanText(text)\n",
    "    tokens = TokenizeText(text)\n",
    "    \n",
    "    #we need to create a new array with pairs of the words in the tokens array.\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(0,len(tokens)-2,1):\n",
    "        firstWord = tokens[i]\n",
    "        secondWord = tokens[i+1]\n",
    "        thirdWord = tokens[i+2]\n",
    "        pairs.append(set([firstWord,secondWord,thirdWord]))\n",
    "    #     print(set([firstWord,secondWord]))\n",
    "#     print(pairs)\n",
    "    return pairs\n",
    "\n",
    "from collections import defaultdict\n",
    "def count_frequency(word_list):\n",
    "    \"\"\" Function input: list object contains strings of individual words.\n",
    "        Function output: defaultdict() object containing {word, frequency} pairs. \"\"\"\n",
    "\n",
    "    freq_counts = defaultdict(int)\n",
    "    \n",
    "    for word in word_list:\n",
    "        freq_counts[word] += 1\n",
    "\n",
    "    return freq_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is', 'this'},\n",
       " {'is', 'my'},\n",
       " {'hate', 'my'},\n",
       " {'hate', 'text'},\n",
       " {'it', 'text'},\n",
       " {'includes', 'it'},\n",
       " {'commas', 'includes'},\n",
       " {'commas', 'question'},\n",
       " {'marks', 'question'},\n",
       " {'dog', 'marks'},\n",
       " {'and', 'dog'},\n",
       " {'and', 'other'},\n",
       " {'other', 'stuff'},\n",
       " {'also', 'stuff'},\n",
       " {'also', 'u'},\n",
       " {'s', 'u'},\n",
       " {'s', 'would'},\n",
       " {'not', 'would'},\n",
       " {'it', 'not'},\n",
       " {'be', 'it'},\n",
       " {'be', 'great'},\n",
       " {'great', 'test'}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GetVerbssFromText(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")\n",
    "# GetAdjectivesFromText(\"This is my text. It includes commas, question marks? and other stuff. Also U.S..\".lower())\n",
    "# #     print(duo[1])\n",
    "# # tokens\n",
    "# GetWordsAndTheirTags(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")\n",
    "\n",
    "# text = CleanText(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")\n",
    "# tokens = TokenizeText(text)  \n",
    "\n",
    "# pairs = []\n",
    "# for i in range(0,len(tokens)-1,1):\n",
    "#     firstWord = tokens[i]\n",
    "#     secondWord = tokens[i+1]\n",
    "#     pairs.append(set([firstWord,secondWord]))\n",
    "# #     print(set([firstWord,secondWord]))\n",
    "# print(pairs)\n",
    "# # tokens.rotate(1)\n",
    "GetWordPairs(\"This is my hate text. It includes commas, question marks? dog and other stuff. Also U.S..wouldn't it be great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to tweak pandas data frames.\n",
    "def AddAdjectiveNounsVerbsToDF(df, textColumn):\n",
    "    df = df.copy()\n",
    "#     amzn_df['text_adjectives'] =amzn_df['review_text'].apply(lambda x: GetAdjectivesFromText(str(x).lower()))\n",
    "#     amzn_df['text_nouns'] =amzn_df['review_text'].apply(lambda x: GetNounsFromText(str(x).lower()))\n",
    "#     amzn_df['text_verbs'] =amzn_df['review_text'].apply(lambda x: GetVerbssFromText(str(x).lower()))\n",
    "    df['text_adjectives'] =df[textColumn].apply(lambda x: GetAdjectivesFromText(str(x).lower()))\n",
    "    df['text_adjectives'] = df['text_adjectives'].apply(lambda row: set([  x for x in row if(len(x) >1)]) )\n",
    "    \n",
    "    df['text_nouns'] =df[textColumn].apply(lambda x: GetNounsFromText(str(x).lower()))\n",
    "    df['text_nouns'] = df['text_nouns'].apply(lambda row: set([  x for x in row if(len(x) >1)]) )\n",
    "    \n",
    "    df['text_verbs'] =df[textColumn].apply(lambda x: GetVerbssFromText(str(x).lower()))\n",
    "    df['text_verbs'] = df['text_verbs'].apply(lambda row: set([  x for x in row if(len(x) >1)]) )\n",
    "    \n",
    "    # create word pairs.\n",
    "    df['text_pairs'] = df[textColumn].apply(lambda row: GetWordPairs(row))\n",
    "    df['text_triplets'] = df[textColumn].apply(lambda row: GetWordTriplets(row))\n",
    "    return df\n",
    "\n",
    "def GetDataframeOfWords(pandasdf, textColumn):\n",
    "#     pandasdf['words'] = CreateListForColumn(pandasdf, textColumn)\n",
    "    pandasdf['words']=pandasdf[textColumn]\n",
    "    wordArray = pandasdf[pandasdf['words'].map(lambda d: len(d)) > 0]['words'].values\n",
    "    words = []\n",
    "    for wordlist in wordArray:\n",
    "        words.extend(wordlist)\n",
    "    wordDictionary = count_frequency(words)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(wordDictionary, orient='index',\n",
    "                       columns=['count']).reset_index()\n",
    "    df = df.rename(columns={\"index\": \"word\"})\n",
    "    df = df.sort_values(by=['count'], ascending=False)\n",
    "    \n",
    "    totalWords = df['count'].sum()\n",
    "    df['usage'] = df['count']/totalWords\n",
    "#     df = df.set_index('word')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>text_adjectives</th>\n",
       "      <th>text_nouns</th>\n",
       "      <th>text_verbs</th>\n",
       "      <th>text_pairs</th>\n",
       "      <th>text_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Airpods Pro deliverðŸ˜Ž</td>\n",
       "      <td>This airpods pro do exactly what apple said th...</td>\n",
       "      <td>{many, different, new}</td>\n",
       "      <td>{money, alot, buds, design, tax, water, apple,...</td>\n",
       "      <td>{buds, design, pro, correctly, noise, know, ma...</td>\n",
       "      <td>[{airpods, this}, {pro, airpods}, {pro, do}, {...</td>\n",
       "      <td>[{airpods, pro, this}, {pro, do, airpods}, {pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>List of Features/Changes compared to Airpods (v2)</td>\n",
       "      <td>Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...</td>\n",
       "      <td>{small, black, previous, closed, pro, audiophi...</td>\n",
       "      <td>{depreciation, place, phones, lows, range, hea...</td>\n",
       "      <td>{depreciation, place, audiophile, squeeze, ran...</td>\n",
       "      <td>[{iphone, like}, {iphone, 11}, {pro, 11}, {pro...</td>\n",
       "      <td>[{iphone, like, 11}, {pro, iphone, 11}, {pro, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Cool but expensive</td>\n",
       "      <td>First review yeh heard about these excited but...</td>\n",
       "      <td>{excited}</td>\n",
       "      <td>{review, dollars, airpods}</td>\n",
       "      <td>{review, like, yeh, heard, get, less, first}</td>\n",
       "      <td>[{review, first}, {review, yeh}, {yeh, heard},...</td>\n",
       "      <td>[{review, first, yeh}, {heard, review, yeh}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Lit</td>\n",
       "      <td>They fire</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{fire}</td>\n",
       "      <td>[{they, fire}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Saved my marriage</td>\n",
       "      <td>With the new transparency mode, I can listen t...</td>\n",
       "      <td>{new}</td>\n",
       "      <td>{street, boys, music, transparency, car, tim, ...</td>\n",
       "      <td>{street, boys, be, transparency, listen, ran, ...</td>\n",
       "      <td>[{the, with}, {the, new}, {new, transparency},...</td>\n",
       "      <td>[{the, new, with}, {the, new, transparency}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  ProductName  review_rating  verified_purchase review_date  \\\n",
       "0        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "1        Apple  AirPods Pro              4                  0  2019-10-30   \n",
       "2        Apple  AirPods Pro              3                  0  2019-10-30   \n",
       "3        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "4        Apple  AirPods Pro              5                  1  2019-10-31   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                               Airpods Pro deliverðŸ˜Ž   \n",
       "1  List of Features/Changes compared to Airpods (v2)   \n",
       "2                                 Cool but expensive   \n",
       "3                                                Lit   \n",
       "4                                  Saved my marriage   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This airpods pro do exactly what apple said th...   \n",
       "1  Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...   \n",
       "2  First review yeh heard about these excited but...   \n",
       "3                                          They fire   \n",
       "4  With the new transparency mode, I can listen t...   \n",
       "\n",
       "                                     text_adjectives  \\\n",
       "0                             {many, different, new}   \n",
       "1  {small, black, previous, closed, pro, audiophi...   \n",
       "2                                          {excited}   \n",
       "3                                                 {}   \n",
       "4                                              {new}   \n",
       "\n",
       "                                          text_nouns  \\\n",
       "0  {money, alot, buds, design, tax, water, apple,...   \n",
       "1  {depreciation, place, phones, lows, range, hea...   \n",
       "2                         {review, dollars, airpods}   \n",
       "3                                                 {}   \n",
       "4  {street, boys, music, transparency, car, tim, ...   \n",
       "\n",
       "                                          text_verbs  \\\n",
       "0  {buds, design, pro, correctly, noise, know, ma...   \n",
       "1  {depreciation, place, audiophile, squeeze, ran...   \n",
       "2       {review, like, yeh, heard, get, less, first}   \n",
       "3                                             {fire}   \n",
       "4  {street, boys, be, transparency, listen, ran, ...   \n",
       "\n",
       "                                          text_pairs  \\\n",
       "0  [{airpods, this}, {pro, airpods}, {pro, do}, {...   \n",
       "1  [{iphone, like}, {iphone, 11}, {pro, 11}, {pro...   \n",
       "2  [{review, first}, {review, yeh}, {yeh, heard},...   \n",
       "3                                     [{they, fire}]   \n",
       "4  [{the, with}, {the, new}, {new, transparency},...   \n",
       "\n",
       "                                       text_triplets  \n",
       "0  [{airpods, pro, this}, {pro, do, airpods}, {pr...  \n",
       "1  [{iphone, like, 11}, {pro, iphone, 11}, {pro, ...  \n",
       "2  [{review, first, yeh}, {heard, review, yeh}, {...  \n",
       "3                                                 []  \n",
       "4  [{the, new, with}, {the, new, transparency}, {...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_df = GetAmazonTextReviewsDf()\n",
    "amzn_df = AddAdjectiveNounsVerbsToDF(amzn_df,'review_text')\n",
    "amzn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>text_adjectives</th>\n",
       "      <th>text_nouns</th>\n",
       "      <th>text_verbs</th>\n",
       "      <th>text_pairs</th>\n",
       "      <th>text_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Airpods Pro deliverðŸ˜Ž</td>\n",
       "      <td>This airpods pro do exactly what apple said th...</td>\n",
       "      <td>{many, different, new}</td>\n",
       "      <td>{money, alot, buds, design, tax, water, apple,...</td>\n",
       "      <td>{buds, design, pro, correctly, noise, know, ma...</td>\n",
       "      <td>[{airpods, this}, {pro, airpods}, {pro, do}, {...</td>\n",
       "      <td>[{airpods, pro, this}, {pro, do, airpods}, {pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>List of Features/Changes compared to Airpods (v2)</td>\n",
       "      <td>Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...</td>\n",
       "      <td>{small, black, previous, closed, pro, audiophi...</td>\n",
       "      <td>{depreciation, place, phones, lows, range, hea...</td>\n",
       "      <td>{depreciation, place, audiophile, squeeze, ran...</td>\n",
       "      <td>[{iphone, like}, {iphone, 11}, {pro, 11}, {pro...</td>\n",
       "      <td>[{iphone, like, 11}, {pro, iphone, 11}, {pro, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Cool but expensive</td>\n",
       "      <td>First review yeh heard about these excited but...</td>\n",
       "      <td>{excited}</td>\n",
       "      <td>{review, dollars, airpods}</td>\n",
       "      <td>{review, like, yeh, heard, get, less, first}</td>\n",
       "      <td>[{review, first}, {review, yeh}, {yeh, heard},...</td>\n",
       "      <td>[{review, first, yeh}, {heard, review, yeh}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Lit</td>\n",
       "      <td>They fire</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{fire}</td>\n",
       "      <td>[{they, fire}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>Saved my marriage</td>\n",
       "      <td>With the new transparency mode, I can listen t...</td>\n",
       "      <td>{new}</td>\n",
       "      <td>{street, boys, music, transparency, car, tim, ...</td>\n",
       "      <td>{street, boys, be, transparency, listen, ran, ...</td>\n",
       "      <td>[{the, with}, {the, new}, {new, transparency},...</td>\n",
       "      <td>[{the, new, with}, {the, new, transparency}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  ProductName  review_rating  verified_purchase review_date  \\\n",
       "0        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "1        Apple  AirPods Pro              4                  0  2019-10-30   \n",
       "2        Apple  AirPods Pro              3                  0  2019-10-30   \n",
       "3        Apple  AirPods Pro              5                  0  2019-10-30   \n",
       "4        Apple  AirPods Pro              5                  1  2019-10-31   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                               Airpods Pro deliverðŸ˜Ž   \n",
       "1  List of Features/Changes compared to Airpods (v2)   \n",
       "2                                 Cool but expensive   \n",
       "3                                                Lit   \n",
       "4                                  Saved my marriage   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This airpods pro do exactly what apple said th...   \n",
       "1  Like iphone 11 Pro, Macbook Pro, Airpad Pro; t...   \n",
       "2  First review yeh heard about these excited but...   \n",
       "3                                          They fire   \n",
       "4  With the new transparency mode, I can listen t...   \n",
       "\n",
       "                                     text_adjectives  \\\n",
       "0                             {many, different, new}   \n",
       "1  {small, black, previous, closed, pro, audiophi...   \n",
       "2                                          {excited}   \n",
       "3                                                 {}   \n",
       "4                                              {new}   \n",
       "\n",
       "                                          text_nouns  \\\n",
       "0  {money, alot, buds, design, tax, water, apple,...   \n",
       "1  {depreciation, place, phones, lows, range, hea...   \n",
       "2                         {review, dollars, airpods}   \n",
       "3                                                 {}   \n",
       "4  {street, boys, music, transparency, car, tim, ...   \n",
       "\n",
       "                                          text_verbs  \\\n",
       "0  {buds, design, pro, correctly, noise, know, ma...   \n",
       "1  {depreciation, place, audiophile, squeeze, ran...   \n",
       "2       {review, like, yeh, heard, get, less, first}   \n",
       "3                                             {fire}   \n",
       "4  {street, boys, be, transparency, listen, ran, ...   \n",
       "\n",
       "                                          text_pairs  \\\n",
       "0  [{airpods, this}, {pro, airpods}, {pro, do}, {...   \n",
       "1  [{iphone, like}, {iphone, 11}, {pro, 11}, {pro...   \n",
       "2  [{review, first}, {review, yeh}, {yeh, heard},...   \n",
       "3                                     [{they, fire}]   \n",
       "4  [{the, with}, {the, new}, {new, transparency},...   \n",
       "\n",
       "                                       text_triplets  \n",
       "0  [{airpods, pro, this}, {pro, do, airpods}, {pr...  \n",
       "1  [{iphone, like, 11}, {pro, iphone, 11}, {pro, ...  \n",
       "2  [{review, first, yeh}, {heard, review, yeh}, {...  \n",
       "3                                                 []  \n",
       "4  [{the, new, with}, {the, new, transparency}, {...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{the, of}</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{t, don}</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{the, on}</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{to, be}</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{cancellation, noise}</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{they, re}</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{airpod, pros}</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{the, with}</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{the, noise}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{cancelling, noise}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{the, sound}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{it, s}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{you, re}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{your, ear}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{you, have}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{you, if}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{far, as}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{ear, tips}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{is, sound}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{the, pro}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{ears, your}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{i, as}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{quality, sound}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{battery, life}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{am, i}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{the, in}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{true, wireless}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{can, i}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{the, bose}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{the, case}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>{you, also}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>{volume, a}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>{break, some}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>{to, seems}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>{traveling, for}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>{click, helpful}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>{loose, them}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>{use, it}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>{volume, knob}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>{the, possibly}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>{3, battery}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>{click, the}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>{with, as}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>{what, out}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>{perhaps, knob}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>{on, vents}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>{the, less}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>{to, work}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>{and, don}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>{the, helpful}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>{loose, to}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>{stick, to}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>{traveling, i}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>{they, perhaps}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>{competent, less}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>{go, to}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>{band, annoying}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>{button, helpful}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>{most, with}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>{apple, unfortunately}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2207 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index  pairs\n",
       "0                  {the, of}     12\n",
       "1                   {t, don}     11\n",
       "2                  {the, on}     10\n",
       "3                   {to, be}     10\n",
       "4      {cancellation, noise}     10\n",
       "5                 {they, re}      9\n",
       "6             {airpod, pros}      9\n",
       "7                {the, with}      9\n",
       "8               {the, noise}      8\n",
       "9        {cancelling, noise}      7\n",
       "10              {the, sound}      7\n",
       "11                   {it, s}      7\n",
       "12                 {you, re}      7\n",
       "13               {your, ear}      7\n",
       "14               {you, have}      7\n",
       "15                 {you, if}      6\n",
       "16                 {far, as}      6\n",
       "17               {ear, tips}      6\n",
       "18               {is, sound}      6\n",
       "19                {the, pro}      6\n",
       "20              {ears, your}      6\n",
       "21                   {i, as}      6\n",
       "22          {quality, sound}      6\n",
       "23           {battery, life}      6\n",
       "24                   {am, i}      6\n",
       "25                 {the, in}      6\n",
       "26          {true, wireless}      6\n",
       "27                  {can, i}      5\n",
       "28               {the, bose}      5\n",
       "29               {the, case}      5\n",
       "...                      ...    ...\n",
       "2177             {you, also}      1\n",
       "2178             {volume, a}      1\n",
       "2179           {break, some}      1\n",
       "2180             {to, seems}      1\n",
       "2181        {traveling, for}      1\n",
       "2182        {click, helpful}      1\n",
       "2183           {loose, them}      1\n",
       "2184               {use, it}      1\n",
       "2185          {volume, knob}      1\n",
       "2186         {the, possibly}      1\n",
       "2187            {3, battery}      1\n",
       "2188            {click, the}      1\n",
       "2189              {with, as}      1\n",
       "2190             {what, out}      1\n",
       "2191         {perhaps, knob}      1\n",
       "2192             {on, vents}      1\n",
       "2193             {the, less}      1\n",
       "2194              {to, work}      1\n",
       "2195              {and, don}      1\n",
       "2196          {the, helpful}      1\n",
       "2197             {loose, to}      1\n",
       "2198             {stick, to}      1\n",
       "2199          {traveling, i}      1\n",
       "2200         {they, perhaps}      1\n",
       "2201       {competent, less}      1\n",
       "2202                {go, to}      1\n",
       "2203        {band, annoying}      1\n",
       "2204       {button, helpful}      1\n",
       "2205            {most, with}      1\n",
       "2206  {apple, unfortunately}      1\n",
       "\n",
       "[2207 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# https://www.mikulskibartosz.name/how-to-split-a-list-inside-a-dataframe-cell-into-rows-in-pandas/\n",
    "\n",
    "# GetDataframeOfWords(amzn_df,'text_adjectives')\n",
    "# GetDataframeOfWords(amzn_df,'text_verbs')\n",
    "def count_frequency_dictionary(word_list):\n",
    "    \"\"\" Function input: list object contains strings of individual words.\n",
    "        Function output: defaultdict() object containing {word, frequency} pairs. \"\"\"\n",
    "\n",
    "    freq_counts = [defaultdict(int)]\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(word)\n",
    "        s1,s2 = word\n",
    "        freq_counts[s1+'-'+s2] += 1\n",
    "\n",
    "    return freq_counts\n",
    "\n",
    "# GetDataframeOfWords(amzn_df[:50],'text_pairs')\n",
    "# from collections import Counter\n",
    "# Counter(amzn_df[:50]['text_pairs'])\n",
    "\n",
    "# amzn_df[:50]['text_pairs'].value_counts()\n",
    "\n",
    "data = amzn_df[40:50][['review_date','verified_purchase','text_pairs']]\n",
    "\n",
    "\n",
    "data['text_pairs']#.apply(lambda x: x[0])\n",
    "\n",
    "# data=data.reset_index()\n",
    "# # data.where(data['text_pairs'])\n",
    "\n",
    "data = data['text_pairs'].apply(pd.Series)\\\n",
    "    .merge(data, right_index = True, left_index = True) \\\n",
    "    .drop([\"text_pairs\"], axis = 1)\\\n",
    "    .melt(id_vars = ['review_date', 'verified_purchase'], value_name = \"pairs\") \\\n",
    "    .drop(\"variable\", axis = 1)\n",
    "\n",
    "\n",
    "# this is where we can drop columns we don't want\n",
    "#     .drop([\"ingredients\"], axis = 1)\\\n",
    "# We can also assign each review an index and make it an id column if we wanted to keep that.\n",
    "data\n",
    "data.pairs.value_counts().reset_index()\n",
    "# data[\"text_pairs\"].values\n",
    "\n",
    "# count_frequency_dictionary(amzn_df[:50]['text_pairs'].value_counts())\n",
    "# dictionary = {}\n",
    "# for elem in amzn_df[:50]['text_pairs']:\n",
    "#     dictionary\n",
    "#     print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
